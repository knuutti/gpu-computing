{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Computing - Exercise 3\n",
        "## Eetu Knutars\n",
        "## 29.1.2025"
      ],
      "metadata": {
        "id": "IdH2it4imDrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1\n",
        "Implement Interleaved reduction kernel."
      ],
      "metadata": {
        "id": "fOAiJbcUkTd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "vWoAlz3lmtUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HRW-uqAhkW_8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the kernel"
      ],
      "metadata": {
        "id": "NGuny-hfmuk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA kernel\n",
        "our_kernel = cp.RawKernel(r''' extern \"C\"\n",
        "__global__ void interleaved_reduction(double* xs, int stride) {\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Check which indeces should be active for the current iteration\n",
        "    if ((index & (2 *stride - 1)) == 0) {\n",
        "        // Update the value for the left cell\n",
        "        xs[index] += xs[index + stride];\n",
        "    }\n",
        "}\n",
        "''', 'interleaved_reduction')"
      ],
      "metadata": {
        "id": "wL4Qg8IUkY0s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating data and calling the kernel"
      ],
      "metadata": {
        "id": "uzB59viwmiqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "vector_size = 2**20\n",
        "numThreadsPerBlock = 32\n",
        "numBlocks = math.ceil(vector_size/numThreadsPerBlock)\n",
        "num_iterations = int(math.log2(vector_size))\n",
        "\n",
        "# Create input vector\n",
        "data_type = np.float64\n",
        "a = cp.random.randn(vector_size, dtype=data_type)\n",
        "a_cpu = cp.asnumpy(a)\n",
        "\n",
        "# Call the kernel\n",
        "for i in range(0, num_iterations):\n",
        "  # Stride is updated every iteration, the vector a is modified\n",
        "  stride = 2**i\n",
        "  our_kernel((numBlocks,1,1),(numThreadsPerBlock,1,1), (a, np.int32(stride)))\n",
        "\n",
        "# Store the results and check if they match\n",
        "result_gpu = cp.asnumpy(a)\n",
        "result_cpu = np.sum(a_cpu)\n",
        "if (np.allclose(result_gpu[0], result_cpu, 0.001, 0.001)):\n",
        "  print(\"They are the same!\")\n",
        "else:\n",
        "  print(\"Something must have gone wrong.:(\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tuC3JbFkkZD",
        "outputId": "01074e70-513f-4afd-dc2f-7f88b66c80b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They are the same!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "Implement Interleaved reduction kernel with shared memory."
      ],
      "metadata": {
        "id": "mb5DuPmfd2Sm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "KFtcWDmIlw4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M5VyaH-qI0c5"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the kernel for interleaved reduction"
      ],
      "metadata": {
        "id": "jD7ofSrSlyj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_kernel = cp.RawKernel(r''' extern \"C\"\n",
        "#define SHARED_DIM 33\n",
        "__global__ void interleaved_reduction(double *xs, double *result, int size)\n",
        "{\n",
        "    __shared__ double shared_xs[SHARED_DIM];\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    shared_xs[tid] = (index < size) ? xs[index] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2) {\n",
        "        if ((tid & (stride * 2 - 1)) == 0)\n",
        "        shared_xs[tid] += shared_xs[tid + stride];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) result[blockIdx.x] = shared_xs[0];\n",
        "\n",
        "}\n",
        "''', 'interleaved_reduction')"
      ],
      "metadata": {
        "id": "5mZW0etV3hl9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate data and calculate the results"
      ],
      "metadata": {
        "id": "G1zy_MeSl53E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "vector_size = 2**20\n",
        "numThreadsPerBlock = 32\n",
        "numBlocks = math.ceil(vector_size/numThreadsPerBlock)\n",
        "num_iterations = int(math.log2(vector_size))\n",
        "\n",
        "# Create input vector\n",
        "data_type = np.float64\n",
        "a = cp.random.randn(vector_size, dtype=data_type)\n",
        "a_cpu = cp.asnumpy(a)\n",
        "\n",
        "# Result vector\n",
        "result = cp.zeros(numBlocks, dtype=data_type)\n",
        "\n",
        "# Call the kernel\n",
        "size = vector_size\n",
        "for i in range(0, num_iterations):\n",
        "  our_kernel((numBlocks,1,1),(numThreadsPerBlock,1,1), (a, result, np.int32(size)))\n",
        "  size = math.ceil(size/numThreadsPerBlock)\n",
        "  a = result\n",
        "\n",
        "# Store the sums for GPU and CPU and check if they are same\n",
        "result_gpu = cp.asnumpy(result)\n",
        "result_cpu = np.sum(a_cpu)\n",
        "if (np.allclose(result_gpu[0], result_cpu, 0.001, 0.001)):\n",
        "  print(\"They are the same!\")\n",
        "else:\n",
        "  print(\"Something must have gone wrong.:(\")"
      ],
      "metadata": {
        "id": "-unKjbaZy54B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb422cd-135b-4ef0-b49e-67cff39c1611"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They are the same!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3\n",
        "Implement Sequential reduction with shared memory."
      ],
      "metadata": {
        "id": "yyTgkZLMd8GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "qBCkCiQ2mZU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "m__OsuIReBuN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining kernel"
      ],
      "metadata": {
        "id": "iNh7wlXtmcF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_kernel = cp.RawKernel(r''' extern \"C\"\n",
        "#define SHARED_DIM 33\n",
        "__global__ void sequential_reduction(double *xs, double *result, int size)\n",
        "{\n",
        "    __shared__ double shared_xs[SHARED_DIM];\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "\n",
        "    // Store data to shared memory\n",
        "    shared_xs[tid] = (index < size) ? xs[index] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Sequential reduction, update the stride in each iteration\n",
        "    for (int stride = blockDim.x/2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            shared_xs[tid] += shared_xs[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Store the value at index 0 to the result vector\n",
        "    if (tid == 0) result[blockIdx.x] = shared_xs[0];\n",
        "\n",
        "}\n",
        "''', 'sequential_reduction')"
      ],
      "metadata": {
        "id": "N1CmBWRYeCL3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data generation and the kernel call for calculating the sum"
      ],
      "metadata": {
        "id": "dk4gcjFqmdgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "\n",
        "vector_size = 2**20\n",
        "numThreadsPerBlock = 32\n",
        "numBlocks = math.ceil(vector_size/numThreadsPerBlock)\n",
        "num_iterations = int(math.log2(vector_size))\n",
        "\n",
        "# Create input vector\n",
        "data_type = np.float64\n",
        "a = cp.random.randn(vector_size, dtype=data_type)\n",
        "a_cpu = cp.asnumpy(a)\n",
        "\n",
        "# Vector for calculating the subresults\n",
        "b = cp.zeros(numBlocks, dtype=data_type)\n",
        "\n",
        "# Call the kernel\n",
        "size = vector_size\n",
        "for i in range(0, num_iterations):\n",
        "  our_kernel((numBlocks,1,1),(numThreadsPerBlock,1,1), (a, b, np.int32(size)))\n",
        "  size = math.ceil(size/numThreadsPerBlock)   # update the block size\n",
        "  a = b                                       # update the input array\n",
        "\n",
        "# Store the sums and check if they are the same\n",
        "result_gpu = cp.asnumpy(b)\n",
        "result_cpu = np.sum(a_cpu)\n",
        "if (np.allclose(result_gpu[0], result_cpu, 0.001, 0.001)):\n",
        "  print(\"They are the same!\")\n",
        "else:\n",
        "  print(\"Something must have gone wrong.:(\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skfosdAgeE5P",
        "outputId": "1777158c-e44f-4268-e06b-5f8918759304"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They are the same!\n"
          ]
        }
      ]
    }
  ]
}